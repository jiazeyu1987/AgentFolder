#!/usr/bin/env python3
"""
llm_communication.py åŠŸèƒ½æµ‹è¯•æ–‡ä»¶

æµ‹è¯•llm_communication.pyä¸­çš„æ¯ä¸ªå‡½æ•°å’Œç±»
æ— éœ€ç¯å¢ƒæ£€æŸ¥ï¼Œä¸“æ³¨äºåŠŸèƒ½éªŒè¯
"""

import os
import sys
import logging
import time
from typing import List, Dict, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def print_section(title: str):
    """æ‰“å°æ ¼å¼åŒ–çš„ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f" {title}")
    print('='*60)

def print_result(test_name: str, result: any, success: bool = True):
    """æ‰“å°æµ‹è¯•ç»“æœ"""
    status = "âœ…" if success else "âŒ"
    print(f"{status} {test_name}")
    if result is not None:
        print(f"   ç»“æœ: {str(result)[:100]}{'...' if len(str(result)) > 100 else ''}")

def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print_section("æµ‹è¯•1: æ¨¡å—å¯¼å…¥")

    try:
        from llm_communication import (
            SimpleLLMService,
            LLMResponse,
            get_llm_service,
            simple_llm_service
        )
        print_result("åŸºç¡€å¯¼å…¥æˆåŠŸ", None, True)
        return {
            'SimpleLLMService': SimpleLLMService,
            'LLMResponse': LLMResponse,
            'get_llm_service': get_llm_service,
            'simple_llm_service': simple_llm_service
        }
    except ImportError as e:
        print_result("æ¨¡å—å¯¼å…¥å¤±è´¥", str(e), False)
        return None

def test_data_classes(classes: dict):
    """æµ‹è¯•æ•°æ®ç±»"""
    print_section("æµ‹è¯•2: æ•°æ®ç±»")

    if not classes:
        print_result("è·³è¿‡æ•°æ®ç±»æµ‹è¯•", "å‰åºæµ‹è¯•å¤±è´¥", False)
        return

    # æµ‹è¯•LLMResponse
    try:
        response = classes['LLMResponse'](
            content="æµ‹è¯•å†…å®¹",
            model="test-model",
            usage={'prompt_tokens': 10, 'completion_tokens': 20, 'total_tokens': 30},
            response_time=1.5,
            provider="test-provider"
        )
        print_result("LLMResponseåˆ›å»ºæˆåŠŸ", f"å†…å®¹: {response.content}, æ¨¡å‹: {response.model}", True)

        # æµ‹è¯•å±æ€§è®¿é—®
        print_result("LLMResponseå±æ€§è®¿é—®",
                    f"provider: {response.provider}, time: {response.response_time}", True)

    except Exception as e:
        print_result("LLMResponseæµ‹è¯•å¤±è´¥", str(e), False)

def test_service_initialization():
    """æµ‹è¯•æœåŠ¡åˆå§‹åŒ–"""
    print_section("æµ‹è¯•3: æœåŠ¡åˆå§‹åŒ–")

    try:
        from llm_communication import SimpleLLMService

        # æµ‹è¯•æ— å‚æ•°åˆå§‹åŒ–
        service1 = SimpleLLMService()
        print_result("æ— å‚æ•°åˆå§‹åŒ–æˆåŠŸ", f"é»˜è®¤æ¨¡å‹: {service1.default_model}", True)

        # æµ‹è¯•å¸¦å‚æ•°åˆå§‹åŒ–
        service2 = SimpleLLMService(api_key="test-key")
        print_result("å¸¦å‚æ•°åˆå§‹åŒ–æˆåŠŸ", f"APIå¯†é’¥å·²è®¾ç½®: {bool(service2.api_key)}", True)

        return service1, service2

    except Exception as e:
        print_result("æœåŠ¡åˆå§‹åŒ–å¤±è´¥", str(e), False)
        return None, None

def test_basic_methods(service):
    """æµ‹è¯•åŸºæœ¬æ–¹æ³•"""
    print_section("æµ‹è¯•4: åŸºæœ¬æ–¹æ³•")

    if not service:
        print_result("è·³è¿‡åŸºæœ¬æ–¹æ³•æµ‹è¯•", "æœåŠ¡åˆå§‹åŒ–å¤±è´¥", False)
        return

    # æµ‹è¯•llm_callæ–¹æ³•
    try:
        prompt = "æµ‹è¯•æç¤ºè¯"
        print(f"ğŸ§ª è°ƒç”¨llm_call: {prompt}")

        start_time = time.time()
        response = service.llm_call(prompt)
        end_time = time.time()

        print_result("llm_callæ–¹æ³•æ‰§è¡Œ",
                    f"å“åº”: {response[:50]}..., è€—æ—¶: {end_time-start_time:.2f}ç§’",
                    True)

    except Exception as e:
        print_result("llm_callæ–¹æ³•å¤±è´¥", str(e), False)

    # æµ‹è¯•simple_llmæ–¹æ³•
    try:
        prompt = "æµ‹è¯•simple_llmæç¤ºè¯"
        print(f"ğŸ§ª è°ƒç”¨simple_llm: {prompt}")

        response = service.simple_llm(prompt, model="claude-3-sonnet-20240229", max_tokens=100)
        print_result("simple_llmæ–¹æ³•æ‰§è¡Œ",
                    f"å“åº”: {response[:50]}...",
                    True)

    except Exception as e:
        print_result("simple_llmæ–¹æ³•å¤±è´¥", str(e), False)

def test_advanced_methods(service):
    """æµ‹è¯•é«˜çº§æ–¹æ³•"""
    print_section("æµ‹è¯•5: é«˜çº§æ–¹æ³•")

    if not service:
        print_result("è·³è¿‡é«˜çº§æ–¹æ³•æµ‹è¯•", "æœåŠ¡åˆå§‹åŒ–å¤±è´¥", False)
        return

    # æµ‹è¯•llm_call_with_history
    try:
        history = [
            {"role": "user", "content": "ä½ å¥½"},
            {"role": "assistant", "content": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}
        ]
        prompt = "ç°åœ¨çš„é—®é¢˜æ˜¯ï¼šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"

        print(f"ğŸ§ª è°ƒç”¨llm_call_with_history: å†å²æ¶ˆæ¯{len(history)}æ¡")

        response = service.llm_call_with_history(prompt, history)
        print_result("llm_call_with_historyæ–¹æ³•æ‰§è¡Œ",
                    f"å“åº”: {response[:50]}...",
                    True)

    except Exception as e:
        print_result("llm_call_with_historyæ–¹æ³•å¤±è´¥", str(e), False)

    # æµ‹è¯•generate_response
    try:
        messages = [
            {"role": "user", "content": "è¯·è§£é‡ŠPythonæ˜¯ä»€ä¹ˆ"},
            {"role": "assistant", "content": "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€"},
            {"role": "user", "content": "å®ƒæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ"}
        ]

        print(f"ğŸ§ª è°ƒç”¨generate_response: æ¶ˆæ¯{len(messages)}æ¡")

        response = service.generate_response(messages)
        print_result("generate_responseæ–¹æ³•æ‰§è¡Œ",
                    f"å†…å®¹: {response.content[:50]}..., æ¨¡å‹: {response.model}",
                    True)

        # æµ‹è¯•LLMResponseå¯¹è±¡
        print_result("LLMResponseå¯¹è±¡éªŒè¯",
                    f"æä¾›å•†æ ‡è®°: {response.provider}, å“åº”æ—¶é—´: {response.response_time:.2f}s",
                    True)

    except Exception as e:
        print_result("generate_responseæ–¹æ³•å¤±è´¥", str(e), False)

def test_utility_methods():
    """æµ‹è¯•å·¥å…·æ–¹æ³•"""
    print_section("æµ‹è¯•6: å·¥å…·æ–¹æ³•")

    try:
        from llm_communication import get_llm_service, simple_llm_service

        # æµ‹è¯•get_llm_service
        service = get_llm_service()
        print_result("get_llm_serviceå‡½æ•°",
                    f"è¿”å›ç±»å‹: {type(service).__name__}",
                    True)

        # æµ‹è¯•å…¨å±€æœåŠ¡å®ä¾‹
        print_result("å…¨å±€æœåŠ¡å®ä¾‹",
                    f"ç±»å‹: {type(simple_llm_service).__name__}",
                    True)

        # æµ‹è¯•quick_testæ–¹æ³•
        test_result = simple_llm_service.quick_test()
        print_result("quick_testæ–¹æ³•",
                    f"æµ‹è¯•ç»“æœ: {test_result}",
                    True)

    except Exception as e:
        print_result("å·¥å…·æ–¹æ³•å¤±è´¥", str(e), False)

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print_section("æµ‹è¯•7: é”™è¯¯å¤„ç†")

    try:
        from llm_communication import SimpleLLMService

        service = SimpleLLMService()

        # æµ‹è¯•ç©ºæç¤ºè¯
        try:
            response = service.llm_call("")
            print_result("ç©ºæç¤ºè¯å¤„ç†",
                        f"å“åº”: {response[:50]}...",
                        True)
        except Exception as e:
            print_result("ç©ºæç¤ºè¯å¼‚å¸¸", str(e), True)

        # æµ‹è¯•éå¸¸é•¿çš„æç¤ºè¯
        try:
            long_prompt = "è¯·è§£é‡Š" + "å¾ˆé•¿" * 1000
            start_time = time.time()
            response = service.llm_call(long_prompt)
            end_time = time.time()
            print_result("é•¿æç¤ºè¯å¤„ç†",
                        f"å“åº”é•¿åº¦: {len(response)}, è€—æ—¶: {end_time-start_time:.2f}s",
                        True)
        except Exception as e:
            print_result("é•¿æç¤ºè¯å¼‚å¸¸", str(e), True)

        # æµ‹è¯•æ— æ•ˆå†å²è®°å½•
        try:
            invalid_history = [{"role": "invalid", "content": "test"}]
            response = service.llm_call_with_history("æµ‹è¯•", invalid_history)
            print_result("æ— æ•ˆå†å²è®°å½•å¤„ç†",
                        f"å“åº”: {response[:50]}...",
                        True)
        except Exception as e:
            print_result("æ— æ•ˆå†å²è®°å½•å¼‚å¸¸", str(e), True)

    except Exception as e:
        print_result("é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥", str(e), False)

def test_performance():
    """æµ‹è¯•æ€§èƒ½"""
    print_section("æµ‹è¯•8: æ€§èƒ½æµ‹è¯•")

    try:
        from llm_communication import simple_llm_service

        test_prompts = [
            "ä»€ä¹ˆæ˜¯Pythonï¼Ÿ",
            "è§£é‡Šæœºå™¨å­¦ä¹ ",
            "ä»€ä¹ˆæ˜¯æ•°æ®åº“ï¼Ÿ"
        ]

        response_times = []

        for i, prompt in enumerate(test_prompts):
            print(f"ğŸ§ª æ€§èƒ½æµ‹è¯• {i+1}/{len(test_prompts)}: {prompt}")

            start_time = time.time()
            response = simple_llm_service.llm_call(prompt)
            end_time = time.time()

            response_time = end_time - start_time
            response_times.append(response_time)

            success = response and not response.startswith("è°ƒç”¨å¤±è´¥")
            print_result(f"æµ‹è¯•{i+1}å®Œæˆ",
                        f"è€—æ—¶: {response_time:.2f}s, æˆåŠŸ: {success}",
                        success)

        if response_times:
            avg_time = sum(response_times) / len(response_times)
            min_time = min(response_times)
            max_time = max(response_times)

            print_result("æ€§èƒ½ç»Ÿè®¡",
                        f"å¹³å‡: {avg_time:.2f}s, æœ€å¿«: {min_time:.2f}s, æœ€æ…¢: {max_time:.2f}s",
                        True)

    except Exception as e:
        print_result("æ€§èƒ½æµ‹è¯•å¤±è´¥", str(e), False)

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ llm_communication.py å®Œæ•´åŠŸèƒ½æµ‹è¯•")
    print("æµ‹è¯•æ‰€æœ‰å‡½æ•°å’Œç±»çš„åŠŸèƒ½")

    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    classes = test_imports()
    test_data_classes(classes)
    service1, service2 = test_service_initialization()
    test_basic_methods(service1)
    test_advanced_methods(service2)
    test_utility_methods()
    test_error_handling()
    test_performance()

    print_section("æµ‹è¯•å®Œæˆæ€»ç»“")
    print("ğŸ“‹ æµ‹è¯•è¦†ç›–çš„åŠŸèƒ½:")
    print("âœ… æ¨¡å—å¯¼å…¥")
    print("âœ… æ•°æ®ç±» (LLMResponse)")
    print("âœ… æœåŠ¡åˆå§‹åŒ–")
    print("âœ… åŸºæœ¬æ–¹æ³• (llm_call, simple_llm)")
    print("âœ… é«˜çº§æ–¹æ³• (llm_call_with_history, generate_response)")
    print("âœ… å·¥å…·æ–¹æ³• (get_llm_service, quick_test)")
    print("âœ… é”™è¯¯å¤„ç†")
    print("âœ… æ€§èƒ½æµ‹è¯•")

    print("\nğŸ‰ æ‰€æœ‰åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print("ğŸ’¡ å¦‚æœæŸäº›æµ‹è¯•å¤±è´¥ï¼Œå¯èƒ½æ˜¯å› ä¸º:")
    print("   1. ç¼ºå°‘ anthropic åŒ…: pip install anthropic")
    print("   2. æ²¡æœ‰é…ç½®è®¤è¯æ–¹å¼ (ç¯å¢ƒå˜é‡æˆ–Claude CLI)")
    print("   3. ç½‘ç»œè¿æ¥é—®é¢˜")

if __name__ == "__main__":
    main()